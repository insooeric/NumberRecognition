{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0989b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have problem here...\n",
    "# eventhough accuracy of this model is 95.6%\n",
    "# when testing with actual hand written image\n",
    "# it shows low confidence (21.1%)...\n",
    "# let's fix this\n",
    "\n",
    "# GOAL: let's try to increase confidence to above 90%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55f23ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# essentially, for each resized images, we want less-noise\n",
    "# by dropping the resolution, we'll get more colored pixels \n",
    "# meaning ai can focus on strocks themselves rather than padding\n",
    "# this means from original 1024 (32 x 32) we change that to 784 (28 x 28)\n",
    "# meaning from input layer -> first hidden layer,\n",
    "# it's now 784 -> 512 (originally 1024 -> 512)\n",
    "# fewer weights results less chance to overfit on random background variation\n",
    "# ok, let's shrink size down from 32 x 32 to 28 x 28\n",
    "\n",
    "# RESULT\n",
    "# yeah, now we've increase the confidence from 21% to 35%\n",
    "# but that's still low..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c866184d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's add one more hidden layer with 64 layers\n",
    "# this way, we'll have 784 -> 512 -> 256 -> 128 -> 64 -> 10\n",
    "\n",
    "# RESULT\n",
    "# ok... we have increased accuracy from 95.6% to around 98% that's good\n",
    "# but the confidence lays around 30%..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26c12d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what if we change the number of neurons for each hidden layer?\n",
    "# let's test out 784 -> 512 -> 384 -> 256 -> 128 -> 10\n",
    "\n",
    "# RESULT\n",
    "# ahhhh... accuracy still bounds around 98%\n",
    "# but the confidence remains the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb0b391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the problem could be softmax\n",
    "# let's try applying sharpening with softmax\n",
    "# we're expecting non-changed accuracy (around 98%) but more confidence\n",
    "\n",
    "# RESULT\n",
    "# hmm... \n",
    "# for 10 random images from test_images, the confidence lays between 95% to 100%\n",
    "# so, we have actually increased the confidence\n",
    "# but for my drawn image, the confidence did increased around 4% (now around 36%)\n",
    "# but it's still low..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7666ad44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's think about the problem\n",
    "# so, trained model guesses my image with confidence around 36%\n",
    "# i've realized the difference between my image and most of the images in test_images\n",
    "# the strock of my image is lower than test images\n",
    "# what if we:\n",
    "#   1. read image\n",
    "#   2. thicken the image several times (top, bottom, left, right)\n",
    "# this way, since the image gets more clear\n",
    "# the confidence increases\n",
    "# let's try it out \n",
    "\n",
    "# RESULT\n",
    "# YES! THE CONFIDENCY INCREASED\n",
    "# from 36% to around 90%"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
